<<<<<<< HEAD
{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\Madina Computers\\OneDrive\\Documents\\Physical-AI-Humanoid-Robotics-Course-Book-main\\sidebars.js","contentPath":"C:\\Users\\Madina Computers\\OneDrive\\Documents\\Physical-AI-Humanoid-Robotics-Course-Book-main\\docs","docs":[{"id":"assessments/assessments","title":"Assessments","description":"Complete assessment system for Physical AI & Humanoid Robotics course","source":"@site/docs/assessments/assessments.mdx","sourceDirName":"assessments","slug":"/assessments/","permalink":"/docs/assessments/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/assessments.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Assessments","description":"Complete assessment system for Physical AI & Humanoid Robotics course","sidebar_position":3}},{"id":"assessments/gazebo-robot-project","title":"Gazebo Project - Build Custom Robot","description":"Design, build, and simulate a custom mobile robot in Gazebo with sensors and navigation capabilities","source":"@site/docs/assessments/gazebo-robot-project.mdx","sourceDirName":"assessments","slug":"/assessments/gazebo-robot-project","permalink":"/docs/assessments/gazebo-robot-project","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/gazebo-robot-project.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Gazebo Project - Build Custom Robot","description":"Design, build, and simulate a custom mobile robot in Gazebo with sensors and navigation capabilities","sidebar_position":1}},{"id":"assessments/ros2-basics-quiz","title":"ROS 2 Basics Quiz","description":"Comprehensive quiz covering ROS 2 fundamentals, architecture, and basic programming concepts","source":"@site/docs/assessments/ros2-basics-quiz.mdx","sourceDirName":"assessments","slug":"/assessments/ros2-basics-quiz","permalink":"/docs/assessments/ros2-basics-quiz","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/ros2-basics-quiz.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"ROS 2 Basics Quiz","description":"Comprehensive quiz covering ROS 2 fundamentals, architecture, and basic programming concepts","sidebar_position":1}},{"id":"assessments/vla-capstone","title":"VLA Capstone - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full Vision-Language-Action capabilities","source":"@site/docs/assessments/vla-capstone.mdx","sourceDirName":"assessments","slug":"/assessments/vla-capstone","permalink":"/docs/assessments/vla-capstone","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/vla-capstone.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"VLA Capstone - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full Vision-Language-Action capabilities","sidebar_position":1}},{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to this comprehensive guide to building intelligent humanoid robots using cutting-edge technologies including ROS 2, simulation platforms, and AI systems.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Introduction to Physical AI & Humanoid Robotics","sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Module Overview","permalink":"/docs/module-1/"}},{"id":"learning-paths/complete-physical-ai","title":"Complete Physical AI Course","description":"Comprehensive 13-week program covering all aspects of physical AI and humanoid robotics. Ideal for students seeking complete mastery of the field.","source":"@site/docs/learning-paths/complete-physical-ai.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/complete-physical-ai","permalink":"/docs/learning-paths/complete-physical-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/complete-physical-ai.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Complete Physical AI Course","description":"Comprehensive 13-week program covering all aspects of physical AI and humanoid robotics. Ideal for students seeking complete mastery of the field.","sidebar_position":1}},{"id":"learning-paths/learning-paths","title":"Learning Paths","description":"Choose your learning journey through Physical AI & Humanoid Robotics","source":"@site/docs/learning-paths/learning-paths.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/","permalink":"/docs/learning-paths/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/learning-paths.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Learning Paths","description":"Choose your learning journey through Physical AI & Humanoid Robotics","sidebar_position":2}},{"id":"learning-paths/quick-start","title":"Quick Start Path","description":"Essential chapters only for rapid deployment. Perfect for teams needing to get started quickly with core concepts.","source":"@site/docs/learning-paths/quick-start.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/quick-start","permalink":"/docs/learning-paths/quick-start","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/quick-start.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Quick Start Path","description":"Essential chapters only for rapid deployment. Perfect for teams needing to get started quickly with core concepts.","sidebar_position":1}},{"id":"learning-paths/robotics-foundations","title":"Robotics Foundations","description":"First 5 weeks focusing on fundamentals. Ideal for beginners building strong foundational knowledge.","source":"@site/docs/learning-paths/robotics-foundations.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/robotics-foundations","permalink":"/docs/learning-paths/robotics-foundations","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/robotics-foundations.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Robotics Foundations","description":"First 5 weeks focusing on fundamentals. Ideal for beginners building strong foundational knowledge.","sidebar_position":1}},{"id":"learning-paths/simulation-specialist","title":"Simulation Specialist","description":"Focused track on robot simulation, digital twins, and virtual testing environments. Perfect for simulation engineers and digital twin developers.","source":"@site/docs/learning-paths/simulation-specialist.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/simulation-specialist","permalink":"/docs/learning-paths/simulation-specialist","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/simulation-specialist.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Simulation Specialist","description":"Focused track on robot simulation, digital twins, and virtual testing environments. Perfect for simulation engineers and digital twin developers.","sidebar_position":1}},{"id":"learning-paths/software-developer","title":"Software Developer Track","description":"Focus on software development aspects: ROS 2 programming and VLA integration. Ideal for software engineers entering robotics.","source":"@site/docs/learning-paths/software-developer.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/software-developer","permalink":"/docs/learning-paths/software-developer","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/software-developer.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Software Developer Track","description":"Focus on software development aspects: ROS 2 programming and VLA integration. Ideal for software engineers entering robotics.","sidebar_position":1}},{"id":"module-1/ch1-1","title":"ROS 2 Architecture & Concepts","description":"Introduction to ROS 2 framework, its architecture, and core concepts for robotic development","source":"@site/docs/module-1/chapter-1.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-1","permalink":"/docs/module-1/ch1-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch1-1","title":"ROS 2 Architecture & Concepts","sidebar_position":1,"duration":10,"difficulty":"beginner"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-1/"},"next":{"title":"Chapter 2: Nodes and Topics","permalink":"/docs/module-1/ch1-2"}},{"id":"module-1/ch1-2","title":"Nodes, Topics, Services & Actions","description":"Deep dive into ROS 2 communication patterns including publish/subscribe, request/response, and goal-based interactions","source":"@site/docs/module-1/chapter-2.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-2","permalink":"/docs/module-1/ch1-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch1-2","title":"Nodes, Topics, Services & Actions","sidebar_position":2,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: ROS 2 Architecture","permalink":"/docs/module-1/ch1-1"},"next":{"title":"Chapter 3: Services and Actions","permalink":"/docs/module-1/ch1-3"}},{"id":"module-1/ch1-3","title":"URDF & Robot Description Formats","description":"Learn to create robot models using Unified Robot Description Format and visual representations","source":"@site/docs/module-1/chapter-3.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-3","permalink":"/docs/module-1/ch1-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch1-3","title":"URDF & Robot Description Formats","sidebar_position":3,"duration":10,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Nodes and Topics","permalink":"/docs/module-1/ch1-2"},"next":{"title":"Chapter 4: URDF and Robot Models","permalink":"/docs/module-1/ch1-4"}},{"id":"module-1/ch1-4","title":"Python rclpy Programming","description":"Develop complete ROS 2 applications using Python client library rclpy","source":"@site/docs/module-1/chapter-4.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-4","permalink":"/docs/module-1/ch1-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch1-4","title":"Python rclpy Programming","sidebar_position":4,"duration":8,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Services and Actions","permalink":"/docs/module-1/ch1-3"},"next":{"title":"Module Overview","permalink":"/docs/module-2/"}},{"id":"module-1/index","title":"The Robotic Nervous System (ROS 2)","description":"Master the Robot Operating System 2 framework for building distributed robotic applications","source":"@site/docs/module-1/index.md","sourceDirName":"module-1","slug":"/module-1/","permalink":"/docs/module-1/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The Robotic Nervous System (ROS 2)","description":"Master the Robot Operating System 2 framework for building distributed robotic applications","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/docs/intro"},"next":{"title":"Chapter 1: ROS 2 Architecture","permalink":"/docs/module-1/ch1-1"}},{"id":"module-2/ch2-1","title":"Gazebo Simulation Environment","description":"Set up and configure Gazebo for robotic simulation with ROS 2 integration","source":"@site/docs/module-2/chapter-1.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-1","permalink":"/docs/module-2/ch2-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch2-1","title":"Gazebo Simulation Environment","sidebar_position":1,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-2/"},"next":{"title":"Chapter 2: Physics and Sensors","permalink":"/docs/module-2/ch2-2"}},{"id":"module-2/ch2-2","title":"Physics Simulation & Collisions","description":"Master physics engines, collision detection, and realistic material properties","source":"@site/docs/module-2/chapter-2.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-2","permalink":"/docs/module-2/ch2-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch2-2","title":"Physics Simulation & Collisions","sidebar_position":2,"duration":10,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo Fundamentals","permalink":"/docs/module-2/ch2-1"},"next":{"title":"Chapter 3: Unity Robotics","permalink":"/docs/module-2/ch2-3"}},{"id":"module-2/ch2-3","title":"Sensor Simulation (LiDAR, Cameras, IMUs)","description":"Simulate various robot sensors including LiDAR, cameras, and inertial measurement units","source":"@site/docs/module-2/chapter-3.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-3","permalink":"/docs/module-2/ch2-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch2-3","title":"Sensor Simulation (LiDAR, Cameras, IMUs)","sidebar_position":3,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Physics and Sensors","permalink":"/docs/module-2/ch2-2"},"next":{"title":"Chapter 4: Advanced Simulation","permalink":"/docs/module-2/ch2-4"}},{"id":"module-2/ch2-4","title":"Environment and Scene Building","description":"Create complex simulation environments and scenes for testing humanoid robots","source":"@site/docs/module-2/chapter-4.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-4","permalink":"/docs/module-2/ch2-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch2-4","title":"Environment and Scene Building","sidebar_position":4,"duration":11,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Unity Robotics","permalink":"/docs/module-2/ch2-3"},"next":{"title":"Module Overview","permalink":"/docs/module-3/"}},{"id":"module-2/index","title":"The Digital Twin (Gazebo & Unity)","description":"Create realistic robot simulations using Gazebo and Unity for testing and development","source":"@site/docs/module-2/index.md","sourceDirName":"module-2","slug":"/module-2/","permalink":"/docs/module-2/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The Digital Twin (Gazebo & Unity)","description":"Create realistic robot simulations using Gazebo and Unity for testing and development","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: URDF and Robot Models","permalink":"/docs/module-1/ch1-4"},"next":{"title":"Chapter 1: Gazebo Fundamentals","permalink":"/docs/module-2/ch2-1"}},{"id":"module-3/ch3-1","title":"NVIDIA Isaac Sim Platform","description":"Introduction to NVIDIA Isaac Sim for photorealistic robot simulation and AI development","source":"@site/docs/module-3/chapter-1.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-1","permalink":"/docs/module-3/ch3-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch3-1","title":"NVIDIA Isaac Sim Platform","sidebar_position":1,"duration":15,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-3/"},"next":{"title":"Chapter 2: AI Integration","permalink":"/docs/module-3/ch3-2"}},{"id":"module-3/ch3-2","title":"Visual SLAM & Perception Pipelines","description":"Implement simultaneous localization and mapping using visual sensors and deep learning","source":"@site/docs/module-3/chapter-2.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-2","permalink":"/docs/module-3/ch3-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch3-2","title":"Visual SLAM & Perception Pipelines","sidebar_position":2,"duration":12,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Isaac Sim Introduction","permalink":"/docs/module-3/ch3-1"},"next":{"title":"Chapter 3: Computer Vision","permalink":"/docs/module-3/ch3-3"}},{"id":"module-3/ch3-3","title":"Path Planning with Nav2","description":"Advanced navigation systems using ROS 2 Navigation 2 framework for autonomous movement","source":"@site/docs/module-3/chapter-3.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-3","permalink":"/docs/module-3/ch3-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch3-3","title":"Path Planning with Nav2","sidebar_position":3,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: AI Integration","permalink":"/docs/module-3/ch3-2"},"next":{"title":"Chapter 4: Machine Learning","permalink":"/docs/module-3/ch3-4"}},{"id":"module-3/ch3-4","title":"Sim-to-Real Transfer Techniques","description":"Bridge the gap between simulation and real-world robot deployment","source":"@site/docs/module-3/chapter-4.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-4","permalink":"/docs/module-3/ch3-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch3-4","title":"Sim-to-Real Transfer Techniques","sidebar_position":4,"duration":10,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Computer Vision","permalink":"/docs/module-3/ch3-3"},"next":{"title":"Module Overview","permalink":"/docs/module-4/"}},{"id":"module-3/index","title":"The AI-Robot Brain (NVIDIA Isaac)","description":"Implement AI-powered robotics using NVIDIA Isaac Sim platform for advanced perception and control","source":"@site/docs/module-3/index.md","sourceDirName":"module-3","slug":"/module-3/","permalink":"/docs/module-3/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The AI-Robot Brain (NVIDIA Isaac)","description":"Implement AI-powered robotics using NVIDIA Isaac Sim platform for advanced perception and control","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Advanced Simulation","permalink":"/docs/module-2/ch2-4"},"next":{"title":"Chapter 1: Isaac Sim Introduction","permalink":"/docs/module-3/ch3-1"}},{"id":"module-4/ch4-1","title":"Voice-to-Action Systems (Whisper)","description":"Implement speech recognition and command interpretation using OpenAI Whisper","source":"@site/docs/module-4/chapter-1.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-1","permalink":"/docs/module-4/ch4-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch4-1","title":"Voice-to-Action Systems (Whisper)","sidebar_position":1,"duration":14,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-4/"},"next":{"title":"Chapter 2: Language Models","permalink":"/docs/module-4/ch4-2"}},{"id":"module-4/ch4-2","title":"LLM-based Cognitive Planning","description":"Utilize Large Language Models for robot task planning and decision making","source":"@site/docs/module-4/chapter-2.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-2","permalink":"/docs/module-4/ch4-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch4-2","title":"LLM-based Cognitive Planning","sidebar_position":2,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: VLA Fundamentals","permalink":"/docs/module-4/ch4-1"},"next":{"title":"Chapter 3: Vision Systems","permalink":"/docs/module-4/ch4-3"}},{"id":"module-4/ch4-3","title":"Multi-modal Interaction Design","description":"Create systems that integrate vision, language, and action for natural robot interaction","source":"@site/docs/module-4/chapter-3.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-3","permalink":"/docs/module-4/ch4-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch4-3","title":"Multi-modal Interaction Design","sidebar_position":3,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Language Models","permalink":"/docs/module-4/ch4-2"},"next":{"title":"Chapter 4: Action Planning","permalink":"/docs/module-4/ch4-4"}},{"id":"module-4/ch4-4","title":"Capstone Project - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full VLA capabilities","source":"@site/docs/module-4/chapter-4.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-4","permalink":"/docs/module-4/ch4-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch4-4","title":"Capstone Project - Autonomous Humanoid","sidebar_position":4,"duration":15,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Vision Systems","permalink":"/docs/module-4/ch4-3"}},{"id":"module-4/index","title":"Vision-Language-Action (VLA)","description":"Integrate vision, language, and action systems for intelligent humanoid robot interaction","source":"@site/docs/module-4/index.md","sourceDirName":"module-4","slug":"/module-4/","permalink":"/docs/module-4/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Vision-Language-Action (VLA)","description":"Integrate vision, language, and action systems for intelligent humanoid robot interaction","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Machine Learning","permalink":"/docs/module-3/ch3-4"},"next":{"title":"Chapter 1: VLA Fundamentals","permalink":"/docs/module-4/ch4-1"}},{"id":"toc","title":"Physical AI & Humanoid Robotics - Table of Contents","description":"Overview","source":"@site/docs/toc.md","sourceDirName":".","slug":"/toc","permalink":"/docs/toc","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/toc.md","tags":[],"version":"current","frontMatter":{}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro","label":"Introduction","translatable":true},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"doc","id":"module-1/index","label":"Module Overview","key":"module1-overview","translatable":true},{"type":"doc","id":"module-1/ch1-1","label":"Chapter 1: ROS 2 Architecture","translatable":true},{"type":"doc","id":"module-1/ch1-2","label":"Chapter 2: Nodes and Topics","translatable":true},{"type":"doc","id":"module-1/ch1-3","label":"Chapter 3: Services and Actions","translatable":true},{"type":"doc","id":"module-1/ch1-4","label":"Chapter 4: URDF and Robot Models","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"doc","id":"module-2/index","label":"Module Overview","key":"module2-overview","translatable":true},{"type":"doc","id":"module-2/ch2-1","label":"Chapter 1: Gazebo Fundamentals","translatable":true},{"type":"doc","id":"module-2/ch2-2","label":"Chapter 2: Physics and Sensors","translatable":true},{"type":"doc","id":"module-2/ch2-3","label":"Chapter 3: Unity Robotics","translatable":true},{"type":"doc","id":"module-2/ch2-4","label":"Chapter 4: Advanced Simulation","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"doc","id":"module-3/index","label":"Module Overview","key":"module3-overview","translatable":true},{"type":"doc","id":"module-3/ch3-1","label":"Chapter 1: Isaac Sim Introduction","translatable":true},{"type":"doc","id":"module-3/ch3-2","label":"Chapter 2: AI Integration","translatable":true},{"type":"doc","id":"module-3/ch3-3","label":"Chapter 3: Computer Vision","translatable":true},{"type":"doc","id":"module-3/ch3-4","label":"Chapter 4: Machine Learning","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"doc","id":"module-4/index","label":"Module Overview","key":"module4-overview","translatable":true},{"type":"doc","id":"module-4/ch4-1","label":"Chapter 1: VLA Fundamentals","translatable":true},{"type":"doc","id":"module-4/ch4-2","label":"Chapter 2: Language Models","translatable":true},{"type":"doc","id":"module-4/ch4-3","label":"Chapter 3: Vision Systems","translatable":true},{"type":"doc","id":"module-4/ch4-4","label":"Chapter 4: Action Planning","translatable":true}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"translate-button-plugin":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}
=======
{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\ShabbirSon\\OneDrive\\Desktop\\Book\\sidebars.js","contentPath":"C:\\Users\\ShabbirSon\\OneDrive\\Desktop\\Book\\docs","docs":[{"id":"assessments/assessments","title":"Assessments","description":"Complete assessment system for Physical AI & Humanoid Robotics course","source":"@site/docs/assessments/assessments.mdx","sourceDirName":"assessments","slug":"/assessments/","permalink":"/docs/assessments/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/assessments.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Assessments","description":"Complete assessment system for Physical AI & Humanoid Robotics course","sidebar_position":3}},{"id":"assessments/gazebo-robot-project","title":"Gazebo Project - Build Custom Robot","description":"Design, build, and simulate a custom mobile robot in Gazebo with sensors and navigation capabilities","source":"@site/docs/assessments/gazebo-robot-project.mdx","sourceDirName":"assessments","slug":"/assessments/gazebo-robot-project","permalink":"/docs/assessments/gazebo-robot-project","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/gazebo-robot-project.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Gazebo Project - Build Custom Robot","description":"Design, build, and simulate a custom mobile robot in Gazebo with sensors and navigation capabilities","sidebar_position":1}},{"id":"assessments/ros2-basics-quiz","title":"ROS 2 Basics Quiz","description":"Comprehensive quiz covering ROS 2 fundamentals, architecture, and basic programming concepts","source":"@site/docs/assessments/ros2-basics-quiz.mdx","sourceDirName":"assessments","slug":"/assessments/ros2-basics-quiz","permalink":"/docs/assessments/ros2-basics-quiz","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/ros2-basics-quiz.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"ROS 2 Basics Quiz","description":"Comprehensive quiz covering ROS 2 fundamentals, architecture, and basic programming concepts","sidebar_position":1}},{"id":"assessments/vla-capstone","title":"VLA Capstone - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full Vision-Language-Action capabilities","source":"@site/docs/assessments/vla-capstone.mdx","sourceDirName":"assessments","slug":"/assessments/vla-capstone","permalink":"/docs/assessments/vla-capstone","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/assessments/vla-capstone.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"VLA Capstone - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full Vision-Language-Action capabilities","sidebar_position":1}},{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to this comprehensive guide to building intelligent humanoid robots using cutting-edge technologies including ROS 2, simulation platforms, and AI systems.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Introduction to Physical AI & Humanoid Robotics","sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Module Overview","permalink":"/docs/module-1/"}},{"id":"learning-paths/complete-physical-ai","title":"Complete Physical AI Course","description":"Comprehensive 13-week program covering all aspects of physical AI and humanoid robotics. Ideal for students seeking complete mastery of the field.","source":"@site/docs/learning-paths/complete-physical-ai.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/complete-physical-ai","permalink":"/docs/learning-paths/complete-physical-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/complete-physical-ai.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Complete Physical AI Course","description":"Comprehensive 13-week program covering all aspects of physical AI and humanoid robotics. Ideal for students seeking complete mastery of the field.","sidebar_position":1}},{"id":"learning-paths/learning-paths","title":"Learning Paths","description":"Choose your learning journey through Physical AI & Humanoid Robotics","source":"@site/docs/learning-paths/learning-paths.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/","permalink":"/docs/learning-paths/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/learning-paths.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Learning Paths","description":"Choose your learning journey through Physical AI & Humanoid Robotics","sidebar_position":2}},{"id":"learning-paths/quick-start","title":"Quick Start Path","description":"Essential chapters only for rapid deployment. Perfect for teams needing to get started quickly with core concepts.","source":"@site/docs/learning-paths/quick-start.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/quick-start","permalink":"/docs/learning-paths/quick-start","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/quick-start.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Quick Start Path","description":"Essential chapters only for rapid deployment. Perfect for teams needing to get started quickly with core concepts.","sidebar_position":1}},{"id":"learning-paths/robotics-foundations","title":"Robotics Foundations","description":"First 5 weeks focusing on fundamentals. Ideal for beginners building strong foundational knowledge.","source":"@site/docs/learning-paths/robotics-foundations.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/robotics-foundations","permalink":"/docs/learning-paths/robotics-foundations","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/robotics-foundations.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Robotics Foundations","description":"First 5 weeks focusing on fundamentals. Ideal for beginners building strong foundational knowledge.","sidebar_position":1}},{"id":"learning-paths/simulation-specialist","title":"Simulation Specialist","description":"Focused track on robot simulation, digital twins, and virtual testing environments. Perfect for simulation engineers and digital twin developers.","source":"@site/docs/learning-paths/simulation-specialist.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/simulation-specialist","permalink":"/docs/learning-paths/simulation-specialist","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/simulation-specialist.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Simulation Specialist","description":"Focused track on robot simulation, digital twins, and virtual testing environments. Perfect for simulation engineers and digital twin developers.","sidebar_position":1}},{"id":"learning-paths/software-developer","title":"Software Developer Track","description":"Focus on software development aspects: ROS 2 programming and VLA integration. Ideal for software engineers entering robotics.","source":"@site/docs/learning-paths/software-developer.mdx","sourceDirName":"learning-paths","slug":"/learning-paths/software-developer","permalink":"/docs/learning-paths/software-developer","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/learning-paths/software-developer.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Software Developer Track","description":"Focus on software development aspects: ROS 2 programming and VLA integration. Ideal for software engineers entering robotics.","sidebar_position":1}},{"id":"module-1/ch1-1","title":"ROS 2 Architecture & Concepts","description":"Introduction to ROS 2 framework, its architecture, and core concepts for robotic development","source":"@site/docs/module-1/chapter-1.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-1","permalink":"/docs/module-1/ch1-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch1-1","title":"ROS 2 Architecture & Concepts","sidebar_position":1,"duration":10,"difficulty":"beginner"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-1/"},"next":{"title":"Chapter 2: Nodes and Topics","permalink":"/docs/module-1/ch1-2"}},{"id":"module-1/ch1-2","title":"Nodes, Topics, Services & Actions","description":"Deep dive into ROS 2 communication patterns including publish/subscribe, request/response, and goal-based interactions","source":"@site/docs/module-1/chapter-2.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-2","permalink":"/docs/module-1/ch1-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch1-2","title":"Nodes, Topics, Services & Actions","sidebar_position":2,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: ROS 2 Architecture","permalink":"/docs/module-1/ch1-1"},"next":{"title":"Chapter 3: Services and Actions","permalink":"/docs/module-1/ch1-3"}},{"id":"module-1/ch1-3","title":"URDF & Robot Description Formats","description":"Learn to create robot models using Unified Robot Description Format and visual representations","source":"@site/docs/module-1/chapter-3.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-3","permalink":"/docs/module-1/ch1-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch1-3","title":"URDF & Robot Description Formats","sidebar_position":3,"duration":10,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Nodes and Topics","permalink":"/docs/module-1/ch1-2"},"next":{"title":"Chapter 4: URDF and Robot Models","permalink":"/docs/module-1/ch1-4"}},{"id":"module-1/ch1-4","title":"Python rclpy Programming","description":"Develop complete ROS 2 applications using Python client library rclpy","source":"@site/docs/module-1/chapter-4.mdx","sourceDirName":"module-1","slug":"/module-1/ch1-4","permalink":"/docs/module-1/ch1-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch1-4","title":"Python rclpy Programming","sidebar_position":4,"duration":8,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Services and Actions","permalink":"/docs/module-1/ch1-3"},"next":{"title":"Module Overview","permalink":"/docs/module-2/"}},{"id":"module-1/index","title":"The Robotic Nervous System (ROS 2)","description":"Master the Robot Operating System 2 framework for building distributed robotic applications","source":"@site/docs/module-1/index.md","sourceDirName":"module-1","slug":"/module-1/","permalink":"/docs/module-1/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-1/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The Robotic Nervous System (ROS 2)","description":"Master the Robot Operating System 2 framework for building distributed robotic applications","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/docs/intro"},"next":{"title":"Chapter 1: ROS 2 Architecture","permalink":"/docs/module-1/ch1-1"}},{"id":"module-2/ch2-1","title":"Gazebo Simulation Environment","description":"Set up and configure Gazebo for robotic simulation with ROS 2 integration","source":"@site/docs/module-2/chapter-1.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-1","permalink":"/docs/module-2/ch2-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch2-1","title":"Gazebo Simulation Environment","sidebar_position":1,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-2/"},"next":{"title":"Chapter 2: Physics and Sensors","permalink":"/docs/module-2/ch2-2"}},{"id":"module-2/ch2-2","title":"Physics Simulation & Collisions","description":"Master physics engines, collision detection, and realistic material properties","source":"@site/docs/module-2/chapter-2.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-2","permalink":"/docs/module-2/ch2-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch2-2","title":"Physics Simulation & Collisions","sidebar_position":2,"duration":10,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo Fundamentals","permalink":"/docs/module-2/ch2-1"},"next":{"title":"Chapter 3: Unity Robotics","permalink":"/docs/module-2/ch2-3"}},{"id":"module-2/ch2-3","title":"Sensor Simulation (LiDAR, Cameras, IMUs)","description":"Simulate various robot sensors including LiDAR, cameras, and inertial measurement units","source":"@site/docs/module-2/chapter-3.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-3","permalink":"/docs/module-2/ch2-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch2-3","title":"Sensor Simulation (LiDAR, Cameras, IMUs)","sidebar_position":3,"duration":12,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Physics and Sensors","permalink":"/docs/module-2/ch2-2"},"next":{"title":"Chapter 4: Advanced Simulation","permalink":"/docs/module-2/ch2-4"}},{"id":"module-2/ch2-4","title":"Environment and Scene Building","description":"Create complex simulation environments and scenes for testing humanoid robots","source":"@site/docs/module-2/chapter-4.mdx","sourceDirName":"module-2","slug":"/module-2/ch2-4","permalink":"/docs/module-2/ch2-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch2-4","title":"Environment and Scene Building","sidebar_position":4,"duration":11,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Unity Robotics","permalink":"/docs/module-2/ch2-3"},"next":{"title":"Module Overview","permalink":"/docs/module-3/"}},{"id":"module-2/index","title":"The Digital Twin (Gazebo & Unity)","description":"Create realistic robot simulations using Gazebo and Unity for testing and development","source":"@site/docs/module-2/index.md","sourceDirName":"module-2","slug":"/module-2/","permalink":"/docs/module-2/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-2/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The Digital Twin (Gazebo & Unity)","description":"Create realistic robot simulations using Gazebo and Unity for testing and development","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: URDF and Robot Models","permalink":"/docs/module-1/ch1-4"},"next":{"title":"Chapter 1: Gazebo Fundamentals","permalink":"/docs/module-2/ch2-1"}},{"id":"module-3/ch3-1","title":"NVIDIA Isaac Sim Platform","description":"Introduction to NVIDIA Isaac Sim for photorealistic robot simulation and AI development","source":"@site/docs/module-3/chapter-1.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-1","permalink":"/docs/module-3/ch3-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch3-1","title":"NVIDIA Isaac Sim Platform","sidebar_position":1,"duration":15,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-3/"},"next":{"title":"Chapter 2: AI Integration","permalink":"/docs/module-3/ch3-2"}},{"id":"module-3/ch3-2","title":"Visual SLAM & Perception Pipelines","description":"Implement simultaneous localization and mapping using visual sensors and deep learning","source":"@site/docs/module-3/chapter-2.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-2","permalink":"/docs/module-3/ch3-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch3-2","title":"Visual SLAM & Perception Pipelines","sidebar_position":2,"duration":12,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Isaac Sim Introduction","permalink":"/docs/module-3/ch3-1"},"next":{"title":"Chapter 3: Computer Vision","permalink":"/docs/module-3/ch3-3"}},{"id":"module-3/ch3-3","title":"Path Planning with Nav2","description":"Advanced navigation systems using ROS 2 Navigation 2 framework for autonomous movement","source":"@site/docs/module-3/chapter-3.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-3","permalink":"/docs/module-3/ch3-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch3-3","title":"Path Planning with Nav2","sidebar_position":3,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: AI Integration","permalink":"/docs/module-3/ch3-2"},"next":{"title":"Chapter 4: Machine Learning","permalink":"/docs/module-3/ch3-4"}},{"id":"module-3/ch3-4","title":"Sim-to-Real Transfer Techniques","description":"Bridge the gap between simulation and real-world robot deployment","source":"@site/docs/module-3/chapter-4.mdx","sourceDirName":"module-3","slug":"/module-3/ch3-4","permalink":"/docs/module-3/ch3-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch3-4","title":"Sim-to-Real Transfer Techniques","sidebar_position":4,"duration":10,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Computer Vision","permalink":"/docs/module-3/ch3-3"},"next":{"title":"Module Overview","permalink":"/docs/module-4/"}},{"id":"module-3/index","title":"The AI-Robot Brain (NVIDIA Isaac)","description":"Implement AI-powered robotics using NVIDIA Isaac Sim platform for advanced perception and control","source":"@site/docs/module-3/index.md","sourceDirName":"module-3","slug":"/module-3/","permalink":"/docs/module-3/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-3/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"The AI-Robot Brain (NVIDIA Isaac)","description":"Implement AI-powered robotics using NVIDIA Isaac Sim platform for advanced perception and control","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Advanced Simulation","permalink":"/docs/module-2/ch2-4"},"next":{"title":"Chapter 1: Isaac Sim Introduction","permalink":"/docs/module-3/ch3-1"}},{"id":"module-4/ch4-1","title":"Voice-to-Action Systems (Whisper)","description":"Implement speech recognition and command interpretation using OpenAI Whisper","source":"@site/docs/module-4/chapter-1.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-1","permalink":"/docs/module-4/ch4-1","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-1.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ch4-1","title":"Voice-to-Action Systems (Whisper)","sidebar_position":1,"duration":14,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Module Overview","permalink":"/docs/module-4/"},"next":{"title":"Chapter 2: Language Models","permalink":"/docs/module-4/ch4-2"}},{"id":"module-4/ch4-2","title":"LLM-based Cognitive Planning","description":"Utilize Large Language Models for robot task planning and decision making","source":"@site/docs/module-4/chapter-2.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-2","permalink":"/docs/module-4/ch4-2","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ch4-2","title":"LLM-based Cognitive Planning","sidebar_position":2,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: VLA Fundamentals","permalink":"/docs/module-4/ch4-1"},"next":{"title":"Chapter 3: Vision Systems","permalink":"/docs/module-4/ch4-3"}},{"id":"module-4/ch4-3","title":"Multi-modal Interaction Design","description":"Create systems that integrate vision, language, and action for natural robot interaction","source":"@site/docs/module-4/chapter-3.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-3","permalink":"/docs/module-4/ch4-3","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"ch4-3","title":"Multi-modal Interaction Design","sidebar_position":3,"duration":13,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Language Models","permalink":"/docs/module-4/ch4-2"},"next":{"title":"Chapter 4: Action Planning","permalink":"/docs/module-4/ch4-4"}},{"id":"module-4/ch4-4","title":"Capstone Project - Autonomous Humanoid","description":"Complete integration project building an autonomous humanoid robot with full VLA capabilities","source":"@site/docs/module-4/chapter-4.mdx","sourceDirName":"module-4","slug":"/module-4/ch4-4","permalink":"/docs/module-4/ch4-4","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/chapter-4.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ch4-4","title":"Capstone Project - Autonomous Humanoid","sidebar_position":4,"duration":15,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Vision Systems","permalink":"/docs/module-4/ch4-3"}},{"id":"module-4/index","title":"Vision-Language-Action (VLA)","description":"Integrate vision, language, and action systems for intelligent humanoid robot interaction","source":"@site/docs/module-4/index.md","sourceDirName":"module-4","slug":"/module-4/","permalink":"/docs/module-4/","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/module-4/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Vision-Language-Action (VLA)","description":"Integrate vision, language, and action systems for intelligent humanoid robot interaction","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Machine Learning","permalink":"/docs/module-3/ch3-4"},"next":{"title":"Chapter 1: VLA Fundamentals","permalink":"/docs/module-4/ch4-1"}},{"id":"toc","title":"Physical AI & Humanoid Robotics - Table of Contents","description":"Overview","source":"@site/docs/toc.md","sourceDirName":".","slug":"/toc","permalink":"/docs/toc","draft":false,"unlisted":false,"editUrl":"https://github.com/neha-haneef115/Physical-AI-Humanoid-Robotics-Course-Book/edit/main/docs/toc.md","tags":[],"version":"current","frontMatter":{}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro","label":"Introduction","translatable":true},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"doc","id":"module-1/index","label":"Module Overview","key":"module1-overview","translatable":true},{"type":"doc","id":"module-1/ch1-1","label":"Chapter 1: ROS 2 Architecture","translatable":true},{"type":"doc","id":"module-1/ch1-2","label":"Chapter 2: Nodes and Topics","translatable":true},{"type":"doc","id":"module-1/ch1-3","label":"Chapter 3: Services and Actions","translatable":true},{"type":"doc","id":"module-1/ch1-4","label":"Chapter 4: URDF and Robot Models","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"doc","id":"module-2/index","label":"Module Overview","key":"module2-overview","translatable":true},{"type":"doc","id":"module-2/ch2-1","label":"Chapter 1: Gazebo Fundamentals","translatable":true},{"type":"doc","id":"module-2/ch2-2","label":"Chapter 2: Physics and Sensors","translatable":true},{"type":"doc","id":"module-2/ch2-3","label":"Chapter 3: Unity Robotics","translatable":true},{"type":"doc","id":"module-2/ch2-4","label":"Chapter 4: Advanced Simulation","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"doc","id":"module-3/index","label":"Module Overview","key":"module3-overview","translatable":true},{"type":"doc","id":"module-3/ch3-1","label":"Chapter 1: Isaac Sim Introduction","translatable":true},{"type":"doc","id":"module-3/ch3-2","label":"Chapter 2: AI Integration","translatable":true},{"type":"doc","id":"module-3/ch3-3","label":"Chapter 3: Computer Vision","translatable":true},{"type":"doc","id":"module-3/ch3-4","label":"Chapter 4: Machine Learning","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"doc","id":"module-4/index","label":"Module Overview","key":"module4-overview","translatable":true},{"type":"doc","id":"module-4/ch4-1","label":"Chapter 1: VLA Fundamentals","translatable":true},{"type":"doc","id":"module-4/ch4-2","label":"Chapter 2: Language Models","translatable":true},{"type":"doc","id":"module-4/ch4-3","label":"Chapter 3: Vision Systems","translatable":true},{"type":"doc","id":"module-4/ch4-4","label":"Chapter 4: Action Planning","translatable":true}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"translate-button-plugin":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}
>>>>>>> 1e24a19805a301e89fd2a6447eb0e6310b793764
